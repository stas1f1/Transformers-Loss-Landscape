# Transformers Loss Landscape Exploration

In this project visualization methods of fine-tuning Transformer architecture
network on QA task were demondstrated. Visualization of the optimal state achieved
by training could be taken into consideration when setting up the
fine-tuning process.

As a result of comparing available corpora and the premise of their
creation, two datasets were selected: [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) and [Adversarial
QA](https://huggingface.co/datasets/adversarial_qa) for the QA task. 
[DistilBERT model](https://huggingface.co/distilbert-base-uncased), chosen for
significant training speed and model configuration weight advantage over
other Transformer models while not compromising accuracy, was trained on
QA task.

<p align="center">
  <img src="https://github.com/stas1f1/VK-User-Analysis/blob/main/User%20profiles.png" width="500" title="hover text">
</p>

<p align="center">
  <img src="https://github.com/stas1f1/VK-User-Analysis/blob/main/total-groups.png" width="500" title="hover text">
  <p align="center">Spam rates throughout groups
</p>
